{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "夜勤明けの帰り電車を待つ\n【検証】食べにくいサンマでも『外科医』が手術道具を使えば綺麗に食えるのか？ | オモコロ\n伊藤詩織さんの言ってることを信じていいのかわからなくなってきた\n伊藤詩織氏への風刺画拡散？「法的措置」発言受けて漫画家が苦しい釈明 - ライブドアニュース\n声優に水樹奈々を起用しないでくれ\n全ファイナルファンタジー大投票｜NHK\n奈良県の「吉野」がマジ本気で良いところなので全力で推したい（寄稿：ヨッピー） | Fun Pay! | あたらしい自分、はじめよう。楽天カード\nもうデザイナーいらないって言われた話【無料デザインツールCanva】 - Qiita\nブログ: すべてのプログラマーが試すべき挑戦的なプロジェクト\n"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://b.hatena.ne.jp/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# 最初のブロックのみ抽出するならfindで問題ない\n",
    "top_entry = soup.find(\"section\", attrs = {\"class\": \"entrylist-unit\"})\n",
    "entries = top_entry.find_all(\"h3\", attrs = {\"class\": \"entrylist-contents-title\"})\n",
    "\n",
    "for entry in entries:\n",
    "    print(entry.find(\"a\").get(\"title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "夜勤明けの帰り電車を待つ\n1131\n【検証】食べにくいサンマでも『外科医』が手術道具を使えば綺麗に食えるのか？ | オモコロ\n559\n伊藤詩織さんの言ってることを信じていいのかわからなくなってきた\n390\n伊藤詩織氏への風刺画拡散？「法的措置」発言受けて漫画家が苦しい釈明 - ライブドアニュース\n373\n声優に水樹奈々を起用しないでくれ\n232\n全ファイナルファンタジー大投票｜NHK\n321\n奈良県の「吉野」がマジ本気で良いところなので全力で推したい（寄稿：ヨッピー） | Fun Pay! | あたらしい自分、はじめよう。楽天カード\n357\nもうデザイナーいらないって言われた話【無料デザインツールCanva】 - Qiita\n466\nブログ: すべてのプログラマーが試すべき挑戦的なプロジェクト\n402\n"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://b.hatena.ne.jp/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# 最初のブロックのみ抽出するならfindで問題ない\n",
    "top_entry = soup.find(\"section\", attrs = {\"class\": \"entrylist-unit\"})\n",
    "entries = top_entry.find_all(\"div\", attrs = {\"class\": \"entrylist-contents\"})\n",
    "\n",
    "for entry in entries:\n",
    "    title_tag = entry.find(\"h3\", attrs = {\"class\": \"entrylist-contents-title\"})\n",
    "    title = title_tag.find(\"a\").get(\"title\")\n",
    "\n",
    "    users_tag = entry.find(\"span\", attrs = {\"class\": \"entrylist-contents-users\"})\n",
    "    users = users_tag.get_text().strip().strip(\" users\")\n",
    "    # strip() 余分な外側の空白、改行や特定の文字を削除\n",
    "\n",
    "    print(title)\n",
    "    print(users)"
   ]
  }
 ]
}